---
title: "Test PLNmodels et gllvm - étude STOC"
author: "StateOfTheR"
format:
  html:
    toc: true
    toc-depth: 4
    number-sections: true
---


```{r librairies}
#| warning: false
#| message: false
#| echo: true
library(PLNmodels)     ## Modèles Poisson log-normal
library(gllvm)         ## Modèles Poisson log-normal (approx laplace)
library(tidyverse)     ## Manipulation et visualisation de données
library(knitr)         ## Manipulation de documents markdown
library(corrplot)      ## Visualisation de matrices
library(igraph)        ## Manipulation de graphes
library(tidygraph)     ## Manipulation de graphes à la mode du tidyverse
library(ggraph)        ## Visualisation de graphes à la mode ggplot
library(future)        ## parallélisation
library(sbm)
```


# Objectif

Dans ce tutoriel nous allons tester les packages {PLNmodels} et {gllvm} sur un jeu de données réels **STOC** réduit aux années 2005 à 2010 où les données d'abondance ont été sommées sur toutes ces années. 

Ces packages ont implémenté des modèles à variables latentes offrant une grande flexibilité dans la modélisation de la dépendance et permettant de tenir compte de la nature de la réponse (comptages). Le modèle PLN (Poisson log-normal) repose sur une modélisation gaussienne de la couche latente, i.e. la dépendance entre les espèces y est décrite par la matrice de covariance du vecteur latent associé à chaque échantillon. A noter que ces modèles permettent de prendre assez facilement en compte l'effet de l'environnement (interactions abiotiques) sur l'abondance des différentes espèces via une régression.

{PLNmodels} comme {gllvm} sont disponibles sur le CRAN et github, donc facilement installables sur R via la commande `install.packages()`:

* https://github.com/PLN-team/PLNmodels
* https://cran.r-project.org/package=PLNmodels
* https://github.com/JenniNiku/gllvm
* https://cran.r-project.org/package=gllvm

L'un comme l'autre utilise pour l'estimation l'inférence variationnelle, avec approximation de Laplace pour {gllvm}.

{PLNmodels} propose en plus de la régression, les méthodes ACP, LDA, analyse de réseaux et modèle de mixture avec implémentation en pyTorch pour les gros jeux de données. {gllvm} a plus développé son modèle de régression en proposant différentes distributions de lien, la possibilité d'ajout de facteurs aléatoires et par défaut une réduction de la dimension par ACP.

Les comparaisons se feront en terme de:

* facilité de mise en forme des données
* modèles proposés
* temps d'execution
* utilisation de la distribution ZIP (zero-inflated poisson)

Ce tutoriel est largement inspiré du tutoriel suivant: https://oliviergimenez.github.io/code_livre_variables_cachees/chiquet.html#%C3%89tapes_pr%C3%A9liminaires.

# Importation des données

```{r}
#climat<-read.table("~/data/stoc_2001_2019/climatic_data.csv",sep=";",header=TRUE)
#cover<-read.table("~/data/stoc_2001_2019/cover_data.csv",sep=";",header=TRUE)
#diversity<-read.table("~/data/stoc_2001_2019/diversity_data.csv",sep=";",header=TRUE)
#stoc<-read.table("~/data/stoc_2001_2019/STOC_2001_2019_noComma.txt",sep="\t",header=TRUE)

load(file="~/gdt/atelieR2024/data/stoc_2001_2019/stoc.rda")

str(stoc)

```

Le dataframe `stoc` est déjà structuré pour une analyse avec le package {PLNmodels}. Il sera donc possiblement à revoir pour {gllmv}. A noter, qu'une fonction existe dans le package permettant de formater les données : `PLNmodels::prepare_data()`.

`stoc` se compose de:

* une matrice d'abondance de 200 espèces par 12 variables
* covariables climatiques: temp et precip
* covariables de couvertures: prefixes de 6 variables "cover_" pourcentage de type de couvertures par site d'observations
* zonebio: zone biogéographique de comptage des espèces - attention caractère
* div: mesure de diversité dans l'unité géographique (richesse spécifique?)
* Offset: vecteur 

Chaque ligne correspond à une série de mesure dans un quadrat de 2km * 2km.

```{r}
table(stoc$zonebio)
```

2 zones avec trop peu de données, nous nous restreignons aux zones Atlantic et Continental.

```{r}
stoc_sub<-filter(stoc,zonebio %in% c("atlantic","continental"))
```

Quelques descriptions des covariables, directement sur `stoc_sub`:

```{r}
# de `temp` à `zonebio`
summary(stoc_sub[,2:11])
```

```{r}
# correlation entre les var de couvertures
cor(stoc_sub[,c(4:10)])
```


```{r}
# verif si somme des couv par lignes vaut 100
sum(stoc_sub[1,4:9])
```

Afin de réduire le nombre de variable on crée une variable type de cover, `type_cover` qui correspond au type de sol le plus représenté dans le quadrat.

```{r}
# Récupération du cover le plus présent
stoc_sub$type_cover <- apply(stoc_sub[,c(4:9)], MARGIN = 1, 
                         FUN = function(x){names(which.max(x))})
```

Nous pouvons directement tester un 1er modèle.

# PLNmodels 

## Modèle PLN standard (regression)

$$Y_i | Z_i \sim \mathcal{P}(\exp Z_i), \quad Z_i \sim \mathcal{N}(m_i,\Sigma)$$

Nombre de paramètres du modèle : $p$ paramètres de moyenne + $p(p+1)/2$ paramètres de covariance, soit :

```{r param}
n <- dim(stoc$Abundance)[1]; p <- dim(stoc$Abundance)[2];
n; p;

# nb param
p + p*(p+1)/2
```


```{r plnstandard}
T0<-Sys.time()
myPLN_M0 <- PLN(Abundance ~ 1, data=stoc_sub)
Sys.time() - T0

# Modèle avec covariables
T0<-Sys.time()
myPLN_M1_temp <- PLNmodels::PLN(Abundance ~ 1 + temp, data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_precip <- PLNmodels::PLN(Abundance ~ 1 + precip, data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_cover_Agricultural <- PLNmodels::PLN(Abundance ~ 1 + cover_Agricultural , data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_cover_Artificial <- PLNmodels::PLN(Abundance ~ 1 + cover_Artificial, data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_cover_Forest <- PLNmodels::PLN(Abundance ~ 1 + cover_Forest, data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_cover_Open <- PLNmodels::PLN(Abundance ~ 1 + cover_Open, data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_cover_Water <- PLNmodels::PLN(Abundance ~ 1 + cover_Water, data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_cover_Wetlands <- PLNmodels::PLN(Abundance ~ 1 + cover_Wetlands, data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_div <- PLNmodels::PLN(Abundance ~ 1 + div, 
                               data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_zonebio <- PLNmodels::PLN(Abundance ~ 1 + zonebio, 
                                   data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_M1_typecover <- PLNmodels::PLN(Abundance ~ 1 + type_cover, 
                                     data = stoc_sub)
Sys.time() - T0

T0<-Sys.time()
myPLN_all <- PLN(Abundance ~ 1 + temp + precip + cover_Agricultural +
               cover_Artificial + cover_Forest + cover_Open + 
               cover_Water + cover_Wetlands + div + zonebio, data=stoc_sub)
Sys.time() - T0

```

Représentation de la matrice de variance-covariance du modèle M0:

```{r varcov1}
heatmap(cov2cor(sigma(myPLN_M0)))
```

Graph des prédictions versus observations pour M0:

```{r}
data.frame(
  fitted   = as.vector(fitted(myPLN_M0)),
  observed = as.vector(stoc_sub$Abundance)
) %>% 
  ggplot(aes(x = observed, y = fitted)) + 
    geom_point(size = .5, alpha =.25 ) +
    geom_abline(intercept = 0, slope = 1, color = "red") +
    scale_x_log10() + 
    scale_y_log10() + 
    theme_bw() + annotation_logticks()
```

Les variables latentes du modèle M0 sont (pour la 1ère espèce) :

```{r latent}
myPLN_M0$latent[1:10,1]
```

Et les positions des variables latentes sans covariates/offsets sont (ici, sans intercept, pour la 1ère espèce) :

```{r latent_pos}
myPLN_M0$latent_pos[1:10,1]

# calcul pour retrouver latent_pos
myPLN_M0$latent[1:10,1] - rep(myPLN_M0$model_par$B[1],10)
```


Sélection meilleur modèle par BIC:

```{r critpln}
# Comparaison des critères

criteria_M0_M1 <- 
  rbind(M0      = myPLN_M0$criteria,
        M1_temp = myPLN_M1_temp$criteria,
        M1_precip = myPLN_M1_precip$criteria,
        M1_cover_agri = myPLN_M1_cover_Agricultural$criteria,
        M1_cover_artificial = myPLN_M1_cover_Artificial$criteria,
        M1_cover_forest = myPLN_M1_cover_Forest$criteria,
        M1_cover_open = myPLN_M1_cover_Open$criteria,
        M1_cover_water = myPLN_M1_cover_Water$criteria,
        M1_cover_wetlands = myPLN_M1_cover_Wetlands$criteria,
        M1_div = myPLN_M1_div$criteria,
        M1_zonebio = myPLN_M1_zonebio$criteria,
        M1_all = myPLN_all$criteria
        ) %>%
    arrange(BIC)

criteria_M0_M1 %>% kable()
```

## Test Corrélation par blocs sur M0

```{r}
covmat<-myPLN_M0 %>% sigma()
heatmap(covmat)

plotMyMatrix(covmat)
```

```{r}
mySimpleSBM<- covmat %>% estimateSimpleSBM(model="gaussian",
                                           dimLabels="species",
                                           estimOptions=list(verbosity=0,
                                                             plot=FALSE))
```

```{r}
plot(mySimpleSBM)
```

## Effet zone biogéographique

```{r}
myPLN_M1_zonebio %>% 
  coefficients() %>% round(1) %>% 
  corrplot(is.corr = FALSE, method = 'color', tl.cex = .5, cl.pos = "n")
```

## Réduction de dimension - PLNPCA

Pour cette méthode qui peut prendre du temps d'exécution, il est possible d'utiliser la parallélisation avec le package {future}:

```{r}
plan(multisession, workers = 4)
```


```{r plnpca}
myPCA_m0 <- PLNmodels::PLNPCA(formula = Abundance ~ 1,
                              data = stoc_sub, 
                              ranks = 1:20)
myPCA_m0
```

```{r}
plot(myPCA_m0)
```

Récupération du "meilleur" modèle suivant le BIC:

```{r pcabic}
model_m0 <- myPCA_m0$getBestModel(crit = "BIC")

# struture de l'objet PLNPCA
model_m0
```

```{r}
ggplot(data.frame(rank = 1:model_m0$rank, 
                  val  = 100 * model_m0$percent_var), 
         aes(x = rank, y = val)) + geom_col() + 
    labs(x = "Axis", y = "Variance (%)")
```

```{r}
plot(model_m0, axes = c(1, 2), map = "individual", ind_cols = stoc_sub$zonebio)
```

```{r}
plot(model_m0, axes = c(1, 2), map = "variable")
```

Matrice de covariance estimée:

```{r}
sigma(model_m0) %>% corrplot(is.corr = FALSE)
```

Possibilité d'utiliser {factoextra} pour accéder aux informations de l'ACP de manière esthétique:

```{r}
factoextra::get_eig(model_m0)
factoextra::get_pca_var(model_m0)
factoextra::get_pca_ind(model_m0)
factoextra::fviz_pca_ind(model_m0)
factoextra::fviz_pca_var(model_m0)
```

```{r}
data.frame(
  fitted   = as.vector(fitted(model_m0)),
  observed = as.vector(stoc_sub$Abundance)
) %>% 
  ggplot(aes(x = observed, y = fitted)) + 
    geom_point(size = .5, alpha =.25 ) +
    geom_abline(intercept = 0, slope = 1, color = "red") +
    scale_x_log10(limits = c(1,1000)) + 
    scale_y_log10(limits = c(1,1000)) + 
    theme_bw() + annotation_logticks()
```


## Analyse linéaire discriminante

**Modèle sans covariable**

Nous utilisons `zonebio` en var discrete, sur le dataset complet `stoc`.

```{r PLNLDA_nocov}
LDA_zonebio_nocov <- PLNLDA(Abundance ~ 0 + offset(log(Offset)),
                            grouping = zonebio, data = stoc)
LDA_zonebio_nocov
sigma(LDA_zonebio_nocov) %>% corrplot::corrplot(is.corr = FALSE)
coef(LDA_zonebio_nocov)
LDA_zonebio_nocov$group_means %>% head() %>% knitr::kable(digits = 2)
plot(LDA_zonebio_nocov)
c(LDA_zonebio_nocov$loglik, LDA_zonebio_nocov$BIC, LDA_zonebio_nocov$ICL)
LDA_zonebio_nocov$scores %>% head %>% knitr::kable(digits = 2)
LDA_zonebio_nocov$corr_map %>% head %>% knitr::kable(digits = 2)
```

**Modèle avec covariables meteo**

```{r PLNLDA_cov}
LDA_zonebio_cov <- PLNLDA(Abundance ~ temp + precip + 0 + offset(log(Offset)),
                          grouping = zonebio, data = stoc)
LDA_zonebio_cov
sigma(LDA_zonebio_cov) %>% corrplot::corrplot(is.corr = FALSE)
coef(LDA_zonebio_cov)
LDA_zonebio_cov$group_means %>% head() %>% knitr::kable(digits = 2)
plot(LDA_zonebio_cov)
c(LDA_zonebio_cov$loglik, LDA_zonebio_cov$BIC, LDA_zonebio_cov$ICL)
LDA_zonebio_cov$scores %>% head %>% knitr::kable(digits = 2)
LDA_zonebio_cov$corr_map %>% head %>% knitr::kable(digits = 2)
```

Les covariables météorologiques semblent bien discriminer/expliquer les zones biologiques.


## Inférence des réseaux

L'objectif est des réseaux est de faire le lien entre les espèces et les covariabbles.

On va tester ici toutes les combinaisons possibles de modèles (attention les combinaisons de modèles à trois variables ne sont pas toutes référencées).

```{r}
models_formula <- c(
  # Modèle sans covariable
  "Abundance ~ 1",
  # Modèle avec une covariable
  "Abundance ~ temp",
  "Abundance ~ precip",
  "Abundance ~ type_cover",
  "Abundance ~ zonebio",
  "Abundance ~ div",
  # Modèle à deux covariables
  "Abundance ~ temp + precip",
  "Abundance ~ temp + type_cover",
  "Abundance ~ temp + zonebio",
  "Abundance ~ temp + div",
  "Abundance ~ precip + type_cover",
  "Abundance ~ precip + zonebio",
  "Abundance ~ precip + div",
  "Abundance ~ type_cover + zonebio",
  "Abundance ~ type_cover + div",
  "Abundance ~ zonebio + div",
  # Modèle à trois covariables
  "Abundance ~ temp + precip + type_cover",
  "Abundance ~ temp + precip + zonebio",
  "Abundance ~ type_cover + precip + zonebio",
  "Abundance ~ type_cover + temp + zonebio",
  "Abundance ~ type_cover + precip + div",
  "Abundance ~ temp + precip + div",
  # Modèle à quatre covariables
  "Abundance ~ temp + precip + type_cover + zonebio",
  "Abundance ~ temp + precip + type_cover + div",
  "Abundance ~ temp + precip + zonebio + div",
  "Abundance ~ temp + type_cover + zonebio + div",
  "Abundance ~ precip + type_cover + zonebio + div",
  # Modèle avec toutes les covariables
  "Abundance ~ temp + precip + type_cover + zonebio + div"
)

```

On fixe les paramètres qui vont nous permettre de comparer les modèles entre eux :

```{r}
lambda <- exp(seq(log(20), log(.01), length.out=10))
subNb <- 2
n <- nrow(stoc_sub)
subSamples <- list(); for(s in 1:subNb){subSamples[[s]] <- sample(1:n, round(.8*n))}
```

Et on estime tous les modèles. Pour plus de rapidité, on va paralléliser la fonction `stabilite_selection` grâce au package `future`.

```{r}
#| eval: FALSE

PLNnet = NULL
## Ajustement de tous les modèles, avec procédure de sélection de pénalité par robustesse des arêtes
for (formula in models_formula[4:28]) {
  network <- PLNnetwork(formula = as.formula(formula), data = stoc, penalties = lambda)
  stability_selection(network, force = TRUE, subsamples = subSamples)
  PLNnet <- c(PLNnet, network)
}
names(PLNnet) = models_formula

# save(PLNnet, file = "data/PLNnet.RData")
# load("data/PLNnet.RData")
```

Dans le bloc ci-dessous on va retravailler un peu les données. On va notamment grouper certains modèles entre eux : modèle sans covariable (`cst`), modèle avec toutes les covariables (`full`), les modèles avec la covariable `type_cover`, les modèles avec la covariable `precip` et les modèles restant `other`.

```{r}
#| eval: FALSE

models <- tibble(
  model   = models_formula, 
  network = PLNnet, 
  group   = case_when(
    model == "Abundance ~ 1 "    ~ "cst", 
    str_detect(model, "precip") & str_detect(model, "temp") & 
      str_detect(model, "zonebio") & str_detect(model, "type_cover") &
      str_detect(model, "div") ~ "full", 
    str_detect(model, "precip") ~ "precip", 
    str_detect(model, "type_cover") ~ "type_cover", 
    TRUE                 ~ "other"
  )
)
plotdata <- models %>% 
  mutate(criteria = map(network, "criteria")) %>% 
  select(-network) %>% 
  unnest(cols = criteria)

# save(plotdata, file = "data/plotdata.RData")

```



```{r}
load("data/plotdata.RData")

manual_palette <- c("cst" = "black", "full" = "red", 
                    "other" = "green", "precip" = "blue", "type_cover"="orange")
ggplot(plotdata, aes(x = param, y = density, group = model, color = group)) + 
  geom_line() + 
  scale_x_log10() + 
  scale_color_manual(values = manual_palette) +
  labs(x = "lambda") + 
  theme(legend.position.inside = c(0.95, 0.95), legend.justification = c(1, 1))

ggplot(plotdata, aes(x = param, group = model, color = group)) + 
  geom_line(aes(y = BIC, linetype = "BIC")) +
  geom_line(aes(y = loglik, linetype = "Loglik")) + 
  geom_vline(xintercept = with(plotdata, param[which.max(BIC)]), linetype = 2) + 
  scale_color_manual(values = manual_palette) +
  scale_x_log10() + 
  labs(x = "lambda")

```


Extraction du meilleur modèle qui maximise le BIC : 

```{r}
best_model <- with(plotdata, model[which.max(BIC)])
best_model
```

À partir du meilleur modèle on extrait la famille de réseau : 

```{r}
# networks <- PLNnet[[best_model]]

load("data/networks.RData")
networks
```

Et enfin on extrait le meilleur modèle du réseau : 

```{r}
# best_network <- networks$getBestModel("BIC")

load("data/best_netword.Rdata")
best_network

```

```{r}
best_network$plot_network()
```


```{r}
# Ne pas oublier de fermer la parallélisation
future::plan("sequential")
```



# gllvm

{gllvm} propose plusieurs distributions de liens quand {PLNmodels} se restreint à la distribution de Poisson et par défaut fait une réduction de la dimension (ACP, paramètre `num.lv` dans la fonction `gllvm()`). {PLNmodels}, dans sa nouvelle version 1.2.0, propose le zero-inflated poisson. Pour comparer les 2 packages, nous allons donc tester sur un modèle standard avec la covariable **type_cover** en fixant le lien à "ZIP" (zero-inflated poisson). Les sorties des 2 fonctions ne sont donc pas directement comparables, il faudra attendre l'implémentation de `ZIPPCA()` dans {PLNmodels} pour pouvoir comparer.

Sur cette section, nous travaillons à nouveau avec le jeu de données complet.

## modèle ZIP

```{r gllvmfit}
#| error: true
#| eval: true
# préparation des matrices en 2 matrices à partir de stoc
Y<-as.matrix(stoc$Abundance)
X<-stoc[,2:10]
studyDesign<-data.frame(sample=as.factor(1:nrow(X)))

mygllvm_all<-gllvm(Y,X,family="negative.binomial")
mygllvm_all

mygllvm_design<-gllvm(Y,X,family="negative.binomial", studyDesign=studyDesign)
mygllvm_design

# avec PLNmodels - bien vérifier d'avoir la version >=1.2.0
T0<-Sys.time()
myplnzip_typecover<- ZIPLN(Abundance ~ 1 + precip , data = stoc)
Sys.time() - T0

# avec gllvm
T0<-Sys.time()
mygllvmzip_typecover<-gllvm(Y, X, family="ZIP", num.lv = 3, 
                          formula = ~ precip)
Sys.time() - T0

```



# Références

1. https://oliviergimenez.github.io/code_livre_variables_cachees/chiquet.html
1. https://pln-team.github.io/PLNmodels/
1. https://hal.science/hal-04033421/document
1. Niku et. al. gllvm: Fast analysis of multivariate abundance data with generalized linear latent variable models in R. 2019. DOI 10.1111/2041_210X.13303 

# Session Info

```{r}
sessionInfo()
```


```{r}
#| echo: false
#| eval: false
T0<-Sys.time()
mygllvm_M0<-gllvm(Y, X, family=poisson(), num.lv = 3, formula = ~ 1)
Sys.time() - T0

# Modèle avec covariable
T0<-Sys.time()
mygllvm_temp<-gllvm(Y, X, family=poisson(), num.lv = 3, formula = ~ temp,
                    offset=log(stoc_sub$offset))
Sys.time() - T0

T0<-Sys.time()
mygllvm_precip<-gllvm(Y, X, family=poisson(), num.lv = 3, formula = ~ precip,
                   offset=log(stoc_sub$Offset))
Sys.time() - T0


T0<-Sys.time()
mygllvm_div<-gllvm(Y, X, family=poisson(), num.lv = 3, formula = ~ div,
                   offset=log(stoc_sub$Offset))
Sys.time() - T0

T0<-Sys.time()
mygllvm_zonebio<-gllvm(Y, X, family=poisson(), num.lv = 3, formula = ~ zonebio,
                   offset=log(stoc_sub$Offset))
Sys.time() - T0

T0<-Sys.time()
mygllvm_all<-gllvm(Y, X, family=poisson(), num.lv = 3, 
                   formula = ~ 1 + temp + precip + cover_Agricultural +
                            cover_Artificial + cover_Forest + cover_Open + 
                            cover_Water + cover_Wetlands + div + zonebio,
                   offset=log(stoc_sub$Offset))
Sys.time() - T0
```

